---
title: pytorchで並列的に学習を行う方法
date: 2022-9-23 11:15:00
categories: [AI]
tags: [Deep Learning, PyTorch, Python, 機械学習, AI, 人工知能, 深層学習]
lang: ja
---

## 1 台のマシンに複数の GPU を使う場合

1 台のマシンに 1 枚のカードの場合、情報はすべて 1 台のマシンにあり、分散はない。
分散トレーニングでは、情報は「分散」され、その分散の仕方の違いを「並列性」と呼ぶことが多い。 通常、分散は「データ並列」(Data Parallelism)と「モデル並列」(Model Parallelism)に分類されるのが通例である。

### データ並列

データ並列処理では、サンプルデータはスライスされ、スライスされたデータは各トレーニングノードに送られ、そこで完全なモデルに対して実行され、複数のノードからの情報がマージされる。

![Data Parallelism](/assert/dp_and_ddp/data_pa.png)

**GPU の観点から説明すると**、各 GPU に同じ構造のモデルを複製し、入力データをミニバッチ単位で分割して並列処理します。その後、各 GPU で計算された勾配を統合・同期することで、全体の学習を進めます。  
具体的な手順は以下の通りです：

1. **データ分割**：CPU が各 GPU に異なるミニバッチデータを配布。
2. **並列計算**：各 GPU でモデルの順伝播・逆伝播を独立して実行。
3. **勾配同期**：各 GPU 間で勾配を収集（AllReduce）し、パラメータを更新。

#### なぜデータ並列が必要か

- **訓練速度の加速**：データ量が増加するにつれて、単一 GPU では訓練時間が過長になるため、複数 GPU で分散処理することで線形近似の高速化を実現します。
- **リソース効率化**：大規模データセット（例：ImageNet）や複雑なモデル（例：ResNet50）において、限られたハードウェアリソースで効率的な学習を可能にします。

#### 線形加速比の具体例

**前提条件**：

- データセット：128 万枚の ImageNet 画像
- モデル：ResNet50
- 単 GPU の最大バッチサイズ：128
- 1 バッチ処理時間：7.2 秒（前処理+順伝播+逆伝播）

**計算**：

- 1 エポックの処理時間：`128万枚 ÷ 128 = 1万バッチ` → `1万 × 7.2秒 = 72,000秒（20時間）`
- 100 エポックの総時間：`20時間 × 100 = 2000時間（約83日）`

**分散環境での比較**：

- 単一 GPU の場合：約 3 か月（非現実的）
- **4 台 ×8GPU（計 32GPU）の場合**：線形加速比を仮定すると、`2000時間 ÷ 32 = 62.5時間（約2.6日）`に短縮されます。

#### 実際の課題

理論的な線形加速比（N 倍の GPU で N 倍速）は理想状態であり、実際には以下のような要因で性能が低下します：

- **通信オーバーヘッド**：GPU 間の勾配同期にかかる時間
- **負荷不均衡**：データ分割や計算リソースの非効率
- **フレームワーク設計**：PyTorch の`DistributedDataParallel`など、実装方式の影響

### モデル並列

モデル並列では、モデルはスライスされ、完全なデータが各トレーニングノードに送られ、そこでスライスされたモデルに対して実行され、複数のノードからの結果がマージされる。

![Model Parallelism](/assert/dp_and_ddp/model_pa.png)

**GPU の観点から説明すると**、モデルの各層（または一部のパラメータ行列）を異なる GPU に配置し、データを順番に処理します。具体的な手順は以下の通りです：

1. **モデル分割**：全体のモデルを GPU0 と GPU1 に分けて配置（例：前半層 →GPU0、後半層 →GPU1）。
2. **順伝播処理**：ミニバッチデータが GPU0 で処理され、その出力結果が GPU1 に送られてさらに処理される。
3. **逆伝播処理**：GPU1 で損失を計算し、勾配を GPU0 に伝播してパラメータ更新を行う。

#### なぜモデル並列が必要か？

- **メモリ制約の解消**：モデルが非常に大きい場合（例：クラス数が膨大な分類タスクで全結合層 FC のパラメータ量が過剰）、単一 GPU の VRAM（ビデオ RAM）ではモデルを保持できないため、複数 GPU に分割して配置する必要があります。
- **スケーラビリティの向上**：データ並列では対応できない超大規模モデル（例：GPT-3 など）の学習を可能にします。

#### 具体例

**前提条件**：

- モデル構造：非常に深いニューラルネットワーク（全結合層のパラメータ量が過大）。
- 単 GPU の VRAM 容量：限界があるため、モデル全体を 1 枚の GPU に載せられない。

**処理の流れ**：

1. **GPU0 の処理**：入力データを前半層で変換。
2. **中間データの転送**：GPU0→GPU1 に中間結果を送信。
3. **GPU1 の処理**：後半層で最終出力を計算し、損失を逆伝播。
4. **勾配の伝播**：GPU1→GPU0 に勾配を送り、各 GPU でパラメータ更新。

## 分布式訓練と集合通信概要

分散型ディープラーニングフレームワークでは、**複数の GPU/ノード間での効率的な通信**がパフォーマンスの鍵を握ります。主な基盤ライブラリは以下の 3 つに分類されます：

1. **集合通信ライブラリ**（例：Open MPI、NCCL、Gloo）
   - 分散トレーニング時の GPU/ノード間通信を担う。
2. **データロード・前処理ライブラリ**（例：NVIDIA DALI）
   - 大規模データセットの高速読み込み・処理を最適化。
3. **分散通信スケジューラーライブラリ**（例：Horovod）
   - MPI/NCCL/Gloo をラップし、PyTorch/TensorFlow などに統一インターフェースを提供。

### 集合通信（Collective Communication）の基礎

集合通信は、**複数プロセス間での一括通信**を実現する仕組みです。MPI（Message Passing Interface）規格で定義される主要な操作は以下の通りです：

#### 代表的な通信操作

| 操作名        | 説明                                                                 | 使用例                       |
| ------------- | -------------------------------------------------------------------- | ---------------------------- |
| **Broadcast** | 1 つのノードのデータを全ノードに配布（1 対 N）                       | モデル初期重みの同期         |
| **Scatter**   | 1 ノードのデータを分割して各ノードに配布                             | ミニバッチデータの分散       |
| **Gather**    | 全ノードのデータを 1 ノードに集約                                    | 分散結果の収集               |
| **Reduce**    | 全ノードのデータを演算（SUM/MAX など）して 1 ノードに集約            | 勾配の総和計算               |
| **Allreduce** | 全ノードのデータを演算後、全ノードに結果を配布（Reduce + Broadcast） | 分散トレーニングでの勾配同期 |
| **Allgather** | 全ノードのデータを全ノードに配布                                     | 分散データの共有             |

#### Allreduce の重要性

データ並列トレーニングでは、各 GPU で計算された**勾配を総和（SUM）して全ノードに同期**する必要があり、これが Allreduce 操作で実現されます。  
例：

1. 各 GPU でローカル勾配を計算
2. Allreduce で総和を取得
3. 全 GPU で同一の更新済みモデルを保証
