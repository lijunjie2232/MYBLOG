---
title: pytorchで並列的に学習を行う方法
date: 2022-9-23 11:15:00
categories: [AI]
tags: [Deep Learning, PyTorch, Python, 機械学習, AI, 人工知能, 深層学習]
lang: ja
---

## 1 台のマシンに複数の GPU を使う場合

1 台のマシンに 1 枚のカードの場合、情報はすべて 1 台のマシンにあり、分散はない。
分散トレーニングでは、情報は「分散」され、その分散の仕方の違いを「並列性」と呼ぶことが多い。 通常、分散は「データ並列」(Data Parallelism)と「モデル並列」(Model Parallelism)に分類されるのが通例である。

### データ並列

データ並列処理では、サンプルデータはスライスされ、スライスされたデータは各トレーニングノードに送られ、そこで完全なモデルに対して実行され、複数のノードからの情報がマージされる。

![Data Parallelism](/assert/dp_and_ddp/data_pa.png)

**GPU の観点から説明すると**、各 GPU に同じ構造のモデルを複製し、入力データをミニバッチ単位で分割して並列処理します。その後、各 GPU で計算された勾配を統合・同期することで、全体の学習を進めます。  
具体的な手順は以下の通りです：

1. **データ分割**：CPU が各 GPU に異なるミニバッチデータを配布。
2. **並列計算**：各 GPU でモデルの順伝播・逆伝播を独立して実行。
3. **勾配同期**：各 GPU 間で勾配を収集（AllReduce）し、パラメータを更新。

#### なぜデータ並列が必要か

- **訓練速度の加速**：データ量が増加するにつれて、単一 GPU では訓練時間が過長になるため、複数 GPU で分散処理することで線形近似の高速化を実現します。
- **リソース効率化**：大規模データセット（例：ImageNet）や複雑なモデル（例：ResNet50）において、限られたハードウェアリソースで効率的な学習を可能にします。

#### 線形加速比の具体例

**前提条件**：

- データセット：128 万枚の ImageNet 画像
- モデル：ResNet50
- 単 GPU の最大バッチサイズ：128
- 1 バッチ処理時間：7.2 秒（前処理+順伝播+逆伝播）

**計算**：

- 1 エポックの処理時間：`128万枚 ÷ 128 = 1万バッチ` → `1万 × 7.2秒 = 72,000秒（20時間）`
- 100 エポックの総時間：`20時間 × 100 = 2000時間（約83日）`

**分散環境での比較**：

- 単一 GPU の場合：約 3 か月（非現実的）
- **4 台 ×8GPU（計 32GPU）の場合**：線形加速比を仮定すると、`2000時間 ÷ 32 = 62.5時間（約2.6日）`に短縮されます。

#### 実際の課題

理論的な線形加速比（N 倍の GPU で N 倍速）は理想状態であり、実際には以下のような要因で性能が低下します：

- **通信オーバーヘッド**：GPU 間の勾配同期にかかる時間
- **負荷不均衡**：データ分割や計算リソースの非効率
- **フレームワーク設計**：PyTorch の`DistributedDataParallel`など、実装方式の影響

### モデル並列

モデル並列では、モデルはスライスされ、完全なデータが各トレーニングノードに送られ、そこでスライスされたモデルに対して実行され、複数のノードからの結果がマージされる。

![Model Parallelism](/assert/dp_and_ddp/model_pa.png)

**GPU の観点から説明すると**、モデルの各層（または一部のパラメータ行列）を異なる GPU に配置し、データを順番に処理します。具体的な手順は以下の通りです：

1. **モデル分割**：全体のモデルを GPU0 と GPU1 に分けて配置（例：前半層 →GPU0、後半層 →GPU1）。
2. **順伝播処理**：ミニバッチデータが GPU0 で処理され、その出力結果が GPU1 に送られてさらに処理される。
3. **逆伝播処理**：GPU1 で損失を計算し、勾配を GPU0 に伝播してパラメータ更新を行う。

#### なぜモデル並列が必要か？
- **メモリ制約の解消**：モデルが非常に大きい場合（例：クラス数が膨大な分類タスクで全結合層FCのパラメータ量が過剰）、単一GPUのVRAM（ビデオRAM）ではモデルを保持できないため、複数GPUに分割して配置する必要があります。
- **スケーラビリティの向上**：データ並列では対応できない超大規模モデル（例：GPT-3など）の学習を可能にします。
