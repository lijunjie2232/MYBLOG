---
title: Transformersã€€ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
date: 2024-3-30 17:10:00
categories: [AI]
tags: [Deep Learning, transformers, æ©Ÿæ¢°å­¦ç¿’, AI, äººå·¥çŸ¥èƒ½, æ·±å±¤å­¦ç¿’]
lang: ja
description: Transformers ã¯ã€PyTorch, TensorFlow, JAX ã«å¯¾å¿œã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€æœ€å…ˆç«¯ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚„ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°èªè­˜ãªã©ã•ã¾ã–ã¾ãªåˆ†é‡ã§ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€æŸ”è»Ÿãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ç›¸äº’é‹ç”¨æ€§ã¨æœ¬ç•ªç’°å¢ƒå‘ã‘ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½ï¼ˆONNX ã‚„ TorchScript å½¢å¼ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰ã‚’æä¾›ã—ã¾ã™ã€‚
---

## ç›®æ¬¡

- [Transformers ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯](#transformers-%E3%83%95%E3%83%AC%E3%83%BC%E3%83%A0%E3%83%AF%E3%83%BC%E3%82%AF)
  - [ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB)
    - [pipã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#pip%E3%81%A7%E3%81%AE%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB)
    - [ç·¨é›†å¯èƒ½ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«](#%E7%B7%A8%E9%9B%86%E5%8F%AF%E8%83%BD%E3%81%AA%E3%82%A4%E3%83%B3%E3%82%B9%E3%83%88%E3%83%BC%E3%83%AB)
    - [ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­å®š](#%E3%82%AD%E3%83%A3%E3%83%83%E3%82%B7%E3%83%A5%E3%81%AE%E8%A8%AD%E5%AE%9A)
    - [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰](#%E3%82%AA%E3%83%95%E3%83%A9%E3%82%A4%E3%83%B3%E3%83%A2%E3%83%BC%E3%83%89)
    - [ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼åˆ©ç”¨æ–¹æ³•](#%E3%82%AA%E3%83%95%E3%83%A9%E3%82%A4%E3%83%B3%E3%81%A7%E3%81%AE%E3%83%A2%E3%83%87%E3%83%AB%E3%83%88%E3%83%BC%E3%82%AF%E3%83%8A%E3%82%A4%E3%82%B6%E3%83%BC%E5%88%A9%E7%94%A8%E6%96%B9%E6%B3%95)
      - [**Model Hub UI** ã‹ã‚‰æ‰‹å‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#model-hub-ui-%E3%81%8B%E3%82%89%E6%89%8B%E5%8B%95%E3%81%A7%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89)
      - [PreTrainedModel.from\_pretrained() \& save\_pretrained() ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼](#pretrainedmodelfrompretrained--savepretrained-%E3%83%AF%E3%83%BC%E3%82%AF%E3%83%95%E3%83%AD%E3%83%BC)
      - [huggingface\_hubãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„ãªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰](#huggingfacehub%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%82%92%E4%BD%BF%E7%94%A8%E3%81%97%E3%81%9F%E3%83%97%E3%83%AD%E3%82%B0%E3%83%A9%E3%83%A0%E7%9A%84%E3%81%AA%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89)
    - [å‚è€ƒ](#%E5%8F%82%E8%80%83)


---

# Transformers ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

Transformers ã¯ã€PyTorch, TensorFlow, JAX ã«å¯¾å¿œã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã€æœ€å…ˆç«¯ã®å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ç°¡å˜ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã¯ã€è‡ªç„¶è¨€èªå‡¦ç†ã‚„ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³ã€éŸ³å£°èªè­˜ãªã©ã•ã¾ã–ã¾ãªåˆ†é‡ã§ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚µãƒãƒ¼ãƒˆã—ã€æŸ”è»Ÿãªãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯é–“ç›¸äº’é‹ç”¨æ€§ã¨æœ¬ç•ªç’°å¢ƒå‘ã‘ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ©Ÿèƒ½ï¼ˆONNX ã‚„ TorchScript å½¢å¼ã¸ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆï¼‰ã‚’æä¾›ã—ã¾ã™ã€‚


## ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
### pipã§ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

- å‰æã¨ã—ã¦ã€Pytorchã¾ãŸã¯tensorflowã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãå¿…è¦ãŒã‚ã‚Šã¾ã™ã€ã•ã‚‰ã«ã€flaxã‚‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™ã€‚


ã“ã‚Œã§ã€æ¬¡ã®ã‚³ãƒãƒ³ãƒ‰ã§ğŸ¤— Transformersã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹æº–å‚™ãŒæ•´ã„ã¾ã—ãŸ:

```
pip install transformers
```

CPUå¯¾å¿œã®ã¿å¿…è¦ãªå ´åˆã€ğŸ¤— Transformersã¨Deep Learningãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’1è¡Œã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã¦ä¾¿åˆ©ã§ã™ã€‚ä¾‹ãˆã°ã€ğŸ¤— Transformersã¨PyTorchã‚’ä»¥ä¸‹ã®ã‚ˆã†ã«ä¸€ç·’ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™:

```
pip install transformers[torch]
```

ğŸ¤— Transformersã¨TensorFlow 2.0:

```
pip install transformers[tf-cpu]
```

ğŸ¤— Transformersã¨Flax:

```
pip install transformers[flax]
```

æœ€å¾Œã«ã€ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹ã“ã¨ã§ğŸ¤— TransformersãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã™:

```
python -c "from transformers import pipeline; print(pipeline('sentiment-analysis')('we love you'))"
```

ãã®å¾Œã€ãƒ©ãƒ™ãƒ«ã¨ã‚¹ã‚³ã‚¢ãŒå‡ºåŠ›ã•ã‚Œã¾ã™:

```
[{'label': 'POSITIVE', 'score': 0.9998704791069031}]
```

### ç·¨é›†å¯èƒ½ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

å¿…è¦ã«å¿œã˜ã¦ã€ç·¨é›†å¯èƒ½ãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚’ã—ã¾ã™:

- ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã®`main`ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ä½¿ã„ã¾ã™ã€‚
- ğŸ¤— Transformersã«ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ãƒˆã—ã€ã‚³ãƒ¼ãƒ‰ã®å¤‰æ›´ã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

ä»¥ä¸‹ã®ã‚³ãƒãƒ³ãƒ‰ã§ãƒ¬ãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³ã—ã¦ã€ğŸ¤— Transformersã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¾ã™:

```
git clone https://github.com/huggingface/transformers.git
cd transformers
pip install -e .
```

### ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®è¨­å®š
- å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ `~/.cache/huggingface/hub` ã«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã•ã‚Œã¾ã™ã€‚
- Windowsã§ã¯ã€`C:\Users\username\.cache\huggingface\hub` ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã™ã€‚
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ä»¥ä¸‹ã®ç’°å¢ƒå¤‰æ•°ã§å¤‰æ›´å¯èƒ½ï¼ˆå„ªå…ˆé †ä½é †ï¼‰:
  1. `HF_HUB_CACHE` or `TRANSFORMERS_CACHE`
  2. `HF_HOME`
  3. `XDG_CACHE_HOME` + `/huggingface`

> âš ï¸ éå»ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§ `PYTORCH_TRANSFORMERS_CACHE` ã¾ãŸã¯ `PYTORCH_PRETRAINED_BERT_CACHE` ã‚’ä½¿ç”¨ã—ã¦ã„ãŸå ´åˆã€ãã‚Œã‚‰ãŒå¼•ãç¶šãä½¿ç”¨ã•ã‚Œã¾ã™ï¼ˆæ˜ç¤ºçš„ã« `TRANSFORMERS_CACHE` ã‚’è¨­å®šã—ã¦ã„ãªã„é™ã‚Šï¼‰ã€‚


### ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰
- ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§ã‚‚å‹•ä½œã•ã›ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ã«ç’°å¢ƒå¤‰æ•°ã‚’è¨­å®šã—ã¾ã™:
  - `HF_HUB_OFFLINE=1`: Hubã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ãªã„
  - `HF_DATASETS_OFFLINE=1`: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚‚ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œ

ä¾‹:
```bash
HF_DATASETS_OFFLINE=1 HF_HUB_OFFLINE=1 \
python examples/pytorch/translation/run_translation.py --model_name_or_path google-t5/t5-small --dataset_name wmt16 --dataset_config ro-en ...
```


### ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ã§ã®ãƒ¢ãƒ‡ãƒ«ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼åˆ©ç”¨æ–¹æ³•
#### **Model Hub UI** ã‹ã‚‰æ‰‹å‹•ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
- Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ä¸Šã® â†“ ã‚¢ã‚¤ã‚³ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã€‚

#### PreTrainedModel.from_pretrained() & save_pretrained() ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
å‰ã‚‚ã£ã¦ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼†ä¿å­˜:
```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("bigscience/T0_3B")
model = AutoModelForSeq2SeqLM.from_pretrained("bigscience/T0_3B")

tokenizer.save_pretrained("./your/path/bigscience_t0")
model.save_pretrained("./your/path/bigscience_t0")
```

ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ç’°å¢ƒã§å†èª­ã¿è¾¼ã¿:
```python
tokenizer = AutoTokenizer.from_pretrained("./your/path/bigscience_t0")
model = AutoModel.from_pretrained("./your/path/bigscience_t0")
```

#### huggingface_hubãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„ãªãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«:
```bash
python -m pip install huggingface_hub
```

ç‰¹å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰:
```python
from huggingface_hub import hf_hub_download

hf_hub_download(repo_id="bigscience/T0_3B", filename="config.json", cache_dir="./your/path/bigscience_t0")
```

ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰å¾Œã«ãƒ­ãƒ¼ãƒ‰:
```python
from transformers import AutoConfig

config = AutoConfig.from_pretrained("./your/path/bigscience_t0/config.json")
```


### å‚è€ƒ
- Hubã‹ã‚‰ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰è©³ç´°ã«ã¤ã„ã¦ã¯ [Transformers official doc](https://huggingface.co/docs/transformers) ã‚’å‚ç…§ã€‚